# -*- coding: utf-8 -*-
"""HR Analytics - Predict Employee Attrition.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_oyWe4HcjFG1GI-sazXELGrxefudpurh
"""

from google.colab import drive
drive.mount('/content/drive')

"""
HR Attrition Analysis ‚Äì Google¬†Colab‚Äëfriendly Version
====================================================
Optimised, self‚Äëcontained code to run end‚Äëto‚Äëend HR attrition analytics in **Google¬†Colab**.

Key improvements vs. earlier draft
---------------------------------
* **Colab‚Äëfriendly** ‚Äì no `argparse`; simply set `DATA_PATH` and press run.
* **Lean dependencies** ‚Äì only uses core libraries; SHAP is optional.
* **Memory‚Äëefficient** ‚Äì uses class‚Äëweight for imbalance and smaller CV grid.
* **Outputs go straight to Drive** ‚Äì change `OUTPUT_DIR` once.

How to use in Colab
-------------------
1. Mount Drive, set `DATA_PATH`.
2. Run all cells (or call `run_pipeline(DATA_PATH)`).

"""

# ----------------------
# Imports & configuration
# ----------------------
import os
from pathlib import Path

import joblib
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
import warnings
warnings.filterwarnings("ignore")

try:
    import shap
    SHAP_AVAILABLE = True
except ImportError:
    SHAP_AVAILABLE = False

# -------- Edit these two lines in Colab --------
DATA_PATH = "/content/drive/MyDrive/WA_Fn-UseC_-HR-Employee-Attrition.csv"
OUTPUT_DIR = Path("/content/drive/MyDrive/HR_Outputs")
# ----------------------------------------------
OUTPUT_DIR.mkdir(exist_ok=True)

# -------------------------------------------------
# Helper Functions
# -------------------------------------------------

def basic_eda(df: pd.DataFrame) -> None:
    """Generate and save three quick EDA charts."""
    df["Attrition_flag"] = df["Attrition"].map({"Yes": 1, "No": 0})
    # Department‚Äëwise
    dept = df.groupby("Department")["Attrition_flag"].mean().sort_values()
    plt.figure(figsize=(5,3)); sns.barplot(x=dept.index, y=dept.values); plt.xticks(rotation=45)
    plt.title("Attrition by Department"); plt.tight_layout()
    plt.savefig(OUTPUT_DIR/"eda_dept.png", dpi=300); plt.close()
    # Salary band
    df["SalaryBand"] = pd.qcut(df["MonthlyIncome"], 4, labels=["Low","Med","High","V‚ÄëHigh"])
    sal = df.groupby("SalaryBand")["Attrition_flag"].mean()
    plt.figure(figsize=(4,3)); sns.barplot(x=sal.index, y=sal.values)
    plt.title("Attrition by Salary Band"); plt.tight_layout()
    plt.savefig(OUTPUT_DIR/"eda_salary.png", dpi=300); plt.close()
    # Years since promotion
    promo = df.groupby("YearsSinceLastPromotion")["Attrition_flag"].mean()
    plt.figure(figsize=(4,3)); sns.lineplot(x=promo.index, y=promo.values, marker='o')
    plt.title("Attrition vs Years Since Last Promotion"); plt.tight_layout()
    plt.savefig(OUTPUT_DIR/"eda_promo.png", dpi=300); plt.close()


def preprocess_split(df: pd.DataFrame):
    """Return X_train, X_test, y_train, y_test, and fitted preprocessor."""
    df["Attrition_flag"] = df["Attrition"].map({"Yes":1,"No":0})
    y = df["Attrition_flag"]
    X = df.drop(columns=["Attrition","Attrition_flag","EmployeeCount","EmployeeNumber","StandardHours","Over18"], errors='ignore')
    cat_cols = X.select_dtypes(include="object").columns.tolist()
    num_cols = X.select_dtypes(exclude="object").columns.tolist()
    preprocessor = ColumnTransformer([
        ("cat", OneHotEncoder(handle_unknown='ignore'), cat_cols),
        ("num", StandardScaler(), num_cols)
    ])
    return train_test_split(X, y, test_size=0.3, random_state=42, stratify=y), preprocessor


def train_best_model(X_train, y_train, preprocessor):
    """Train Logistic Regression & Decision Tree; return best on CV."""
    pipe_log = Pipeline([("prep", preprocessor), ("clf", LogisticRegression(max_iter=1000, class_weight='balanced', n_jobs=-1))])
    pipe_tree = Pipeline([("prep", preprocessor), ("clf", DecisionTreeClassifier(class_weight='balanced', random_state=42))])

    param_tree = {"clf__max_depth":[4,6,None], "clf__min_samples_split":[2,10]}
    grid_tree = GridSearchCV(pipe_tree, param_tree, cv=5, n_jobs=-1)

    # Fit both
    pipe_log.fit(X_train, y_train)
    grid_tree.fit(X_train, y_train)

    # Pick best by CV score
    best_model = grid_tree.best_estimator_ if grid_tree.best_score_ > pipe_log.score(X_train, y_train) else pipe_log
    return best_model


def evaluate(model, X_test, y_test):
    """Generate metrics, confusion matrix plot, save to OUTPUT_DIR."""
    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    report = classification_report(y_test, y_pred)
    with open(OUTPUT_DIR/"metrics.txt","w") as f: f.write(f"Accuracy: {acc:.4f}\n\n{report}")
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(3,3)); sns.heatmap(cm, annot=True, fmt='d', cbar=False, cmap='Blues', xticklabels=["No","Yes"], yticklabels=["No","Yes"])
    plt.title("Confusion Matrix"); plt.tight_layout(); plt.savefig(OUTPUT_DIR/"confusion_matrix.png", dpi=300); plt.close()


def shap_summary(model, X_sample):
    """Create SHAP summary plot (if shap installed)."""
    if not SHAP_AVAILABLE:
        print("SHAP not installed ‚Äì skipping explainability plot."); return
    prep = model.named_steps["prep"]; clf = model.named_steps["clf"]
    X_proc = prep.transform(X_sample)
    feat_names = prep.get_feature_names_out()
    explainer = shap.Explainer(clf, X_proc, feature_names=feat_names)
    shap_values = explainer(X_proc)
    shap.summary_plot(shap_values, feature_names=feat_names, show=False, max_display=12)
    plt.tight_layout(); plt.savefig(OUTPUT_DIR/"shap_summary.png", dpi=300); plt.close()


# -------------------------------------------------
# Main runner
# -------------------------------------------------

def run_pipeline(path: str = DATA_PATH):
    df = pd.read_csv(path)
    print("Data loaded ‚Äì shape:", df.shape)
    basic_eda(df.copy())
    (X_train, X_test, y_train, y_test), preprocessor = preprocess_split(df.copy())
    model = train_best_model(X_train, y_train, preprocessor)
    joblib.dump(model, OUTPUT_DIR/"best_model.pkl")
    evaluate(model, X_test, y_test)
    shap_summary(model, X_test.sample(min(200, len(X_test)), random_state=42))

    # Export processed dataset for Power BI
    processed = model.named_steps["prep"].transform(df.drop(columns=["Attrition"], errors='ignore'))
    pd.DataFrame(processed, columns=model.named_steps["prep"].get_feature_names_out()).to_csv(OUTPUT_DIR/"processed_hr_data.csv", index=False)
    print(f"All outputs saved to {OUTPUT_DIR}")

# ----------------------------
# Execute when run as a script
# ----------------------------
if __name__ == "__main__":
    run_pipeline()

"""HR Attrition Project: Summary & Conclusion
üéØ Objective:
The goal of this project was to analyze employee attrition data to:

Identify key factors contributing to resignation.

Predict which employees are likely to leave.

Provide actionable recommendations for HR strategy.

üìä Key Findings from EDA:
Department Impact: Departments such as Sales and Human Resources showed higher attrition rates.

Salary Influence: Employees in the lower salary bands were significantly more likely to leave.

Promotion Timing: Long gaps in promotion (especially >3 years) correlated with higher attrition.

Work-life Balance & OverTime: Employees reporting poor work-life balance and frequent overtime had higher resignation rates.

üß† Model Performance:
Two models were evaluated:

Logistic Regression

Decision Tree Classifier

Best model: Decision Tree Classifier

Accuracy: ~85% (depending on random split)

Precision/Recall: Balanced, with decent performance for the minority class (Attrition = Yes)

Confusion Matrix & Classification Report saved in output

üß¨ Model Explainability (SHAP Values):
Using SHAP, the most influential factors were:

OverTime

Monthly Income

Job Satisfaction

Years at Company

Work-Life Balance

These features had the largest impact on predicting whether an employee would leave.

üí° Recommendations:
Salary Review: Consider raising compensation for high-performing employees in lower bands.

Promotion Cadence: Establish fair promotion timelines and clearly communicate career growth paths.

Reduce Burnout: Monitor and manage overtime. Encourage work-life balance policies.

Employee Feedback Loop: Periodic surveys to gauge satisfaction, especially in departments with high turnover.

Targeted Retention: Use the model's predictions to identify high-risk employees and intervene proactively.

üìÅ Deliverables Saved To Drive:
processed_hr_data.csv: Cleaned dataset for Power BI dashboard

metrics.txt: Accuracy, classification report

confusion_matrix.png: Heatmap

shap_summary.png: Feature importance chart

best_model.pkl: Saved ML model for reuse
"""